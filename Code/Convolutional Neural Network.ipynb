{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from skimage.io import imread, imshow, imsave\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainlabel = pd.read_csv('../Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nb_classes = 447\n",
    "nb_epoch = 3\n",
    "data_augmentation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shape of the image (SHAPE x SHAPE)\n",
    "shapex, shapey = 200, 300\n",
    "# number of convolutional filters to use at each layer\n",
    "nb_filters = [32, 64]\n",
    "# level of pooling to perform at each layer (POOL x POOL)\n",
    "nb_pool = [2, 2]\n",
    "# level of convolution to perform at each layer (CONV x CONV)\n",
    "nb_conv = [3, 3]\n",
    "# the MNIST images are greyscale\n",
    "image_dimensions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dloc = '../../BigData/kaggle-right-whale/imgs/'\n",
    "#features = []\n",
    "#for image in trainlabel['Image']:\n",
    "#    dfile = dloc + image\n",
    "#    splitfile = os.path.splitext(file)\n",
    "#    fsmall = splitfile[0] + '_small' + splitfile[1]\n",
    "#    imdata = imread(fsmall)\n",
    "#    features.append(imdata.flatten())\n",
    "features = []\n",
    "foundlist = []\n",
    "files = glob(dloc + '*_small.jpg')\n",
    "for i in range(len(files)):\n",
    "    si = str(i)\n",
    "    tailloc = 'w_' + si + '_small.jpg'\n",
    "    dfile = dloc + tailloc\n",
    "    if 'w_' + si + '.jpg' in trainlabel['Image'].values and dfile in files:\n",
    "        imdata = imread(dfile)\n",
    "        features.append(np.reshape(imdata, (3, 200, 300)))\n",
    "        trainlabelindex = trainlabel['Image'].values == 'w_' + si + '.jpg'\n",
    "        trainlabelvalue = trainlabel['whaleID'].values[trainlabelindex][0]\n",
    "        foundlist.append(trainlabelvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4543, 3, 200, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = features\n",
    "y = vectorizer.fit_transform(foundlist).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4543, 447)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3180, 3, 200, 300)\n",
      "3180 train samples\n",
      "1363 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between tran and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4543, 447)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(nb_filters[0], image_dimensions, nb_conv[0], nb_conv[0], border_mode='full'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters[0], nb_filters[0], nb_conv[0], nb_conv[0]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(nb_pool[0], nb_pool[0])))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(nb_filters[1], nb_filters[0], nb_conv[0], nb_conv[0], border_mode='full'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters[1], nb_filters[1], nb_conv[1], nb_conv[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(nb_pool[1], nb_pool[1])))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the image dimensions are the original dimensions divided by any pooling\n",
    "# each pixel has a number of filters, determined by the last Convolution2D layer\n",
    "model.add(Dense(nb_filters[-1] * (shapex / nb_pool[0] / nb_pool[1]) * (shapey / nb_pool[0] / nb_pool[1]), 512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(512, nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's train the model using SGD + momentum (how original).\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation or normalization\n",
      "Epoch 0"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print(\"Not using data augmentation or normalization\")\n",
    "\n",
    "    X_train = X_train.astype(\"float32\")\n",
    "    X_test = X_test.astype(\"float32\")\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "\n",
    "else:\n",
    "    print(\"Using real time data augmentation\")\n",
    "\n",
    "    # this will do preprocessing and realtime data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    for e in range(nb_epoch):\n",
    "        print('-'*40)\n",
    "        print('Epoch', e)\n",
    "        print('-'*40)\n",
    "        print(\"Training...\")\n",
    "        # batch train with realtime data augmentation\n",
    "        progbar = generic_utils.Progbar(X_train.shape[0])\n",
    "        for X_batch, Y_batch in datagen.flow(X_train, Y_train):\n",
    "            loss = model.train_on_batch(X_batch, Y_batch)\n",
    "            progbar.add(X_batch.shape[0], values=[(\"train loss\", loss)])\n",
    "\n",
    "        print(\"Testing...\")\n",
    "        # test time!\n",
    "        progbar = generic_utils.Progbar(X_test.shape[0])\n",
    "        for X_batch, Y_batch in datagen.flow(X_test, Y_test):\n",
    "            score = model.test_on_batch(X_batch, Y_batch)\n",
    "            progbar.add(X_batch.shape[0], values=[(\"test loss\", score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image = makeImage(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ypredict = model.predict(test_image, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfpredict = pd.DataFrame(np.argmax(ypredict, axis=1))\n",
    "dfpredict.columns = ['Label']\n",
    "dfpredict['ImageId'] = np.arange(28000) + 1\n",
    "dfpredict.to_csv('../Data/predict_CNNbenchmark.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(ypredict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
