{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from skimage.io import imread, imshow, imsave\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainlabel = pd.read_csv('../Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_classes = 447\n",
    "nb_epoch = 3\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shape of the image (SHAPE x SHAPE)\n",
    "shapex, shapey = 200, 300\n",
    "# number of convolutional filters to use at each layer\n",
    "nb_filters = 32\n",
    "# level of pooling to perform at each layer (POOL x POOL)\n",
    "nb_pool = 2\n",
    "# level of convolution to perform at each layer (CONV x CONV)\n",
    "nb_conv = 3\n",
    "# the MNIST images are greyscale\n",
    "image_dimensions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dloc = '../../BigData/kaggle-right-whale/imgs/'\n",
    "features = []\n",
    "features_test = []\n",
    "foundlist = []\n",
    "foundlist_test = []\n",
    "files = glob(dloc + '*_small.jpg')\n",
    "for ifile in files:\n",
    "    filesplit = os.path.splitext(ifile)\n",
    "    endindex = ifile.index('_small')\n",
    "    startindex = ifile.index('w_')\n",
    "    imloc = ifile[startindex:endindex] + '.jpg'\n",
    "    if imloc in trainlabel['Image'].values:\n",
    "        #print('Found ' + imloc + ' in train set.')\n",
    "        imdata = imread(ifile)\n",
    "        features.append(np.reshape(imdata, (3, 200, 300)))\n",
    "        trainlabelindex = trainlabel['Image'].values == imloc\n",
    "        trainlabelvalue = trainlabel['whaleID'].values[trainlabelindex][0]\n",
    "        foundlist.append(trainlabelvalue)\n",
    "    else:\n",
    "        #print('Found ' + imloc + ' in test set.')\n",
    "        imdata = imread(ifile)\n",
    "        features_test.append(np.reshape(imdata, (3, 200, 300)))\n",
    "        foundlist_test.append(imloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_test = np.array(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6925"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(foundlist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4543, 3, 200, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6925, 3, 200, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = features\n",
    "y = vectorizer.fit_transform(foundlist).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4543, 447)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3180, 3, 200, 300)\n",
      "3180 train samples\n",
      "1363 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between tran and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4543, 447)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapted from MNIST example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, 3, nb_conv, nb_conv, border_mode='full'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, nb_filters, nb_conv, nb_conv))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "# the resulting image after conv and pooling is the original shape\n",
    "# divided by the pooling with a number of filters for each \"pixel\"\n",
    "# (the number of filters is determined by the last Conv2D)\n",
    "model.add(Dense(nb_filters * (shapex / nb_pool) * (shapey / nb_pool), 128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3180 samples, validate on 1363 samples\n",
      "Epoch 0\n",
      "  32/3180 [..............................] - ETA: 7841s - loss: 20.2508 - acc: 0.0000"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, show_accuracy=True, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapted from CIFAR10 example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(nb_filters[0], image_dimensions, nb_conv[0], nb_conv[0], border_mode='full'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters[0], nb_filters[0], nb_conv[0], nb_conv[0]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(nb_pool[0], nb_pool[0])))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(nb_filters[1], nb_filters[0], nb_conv[0], nb_conv[0], border_mode='full'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters[1], nb_filters[1], nb_conv[1], nb_conv[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(nb_pool[1], nb_pool[1])))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the image dimensions are the original dimensions divided by any pooling\n",
    "# each pixel has a number of filters, determined by the last Convolution2D layer\n",
    "model.add(Dense(nb_filters[-1] * (shapex / nb_pool[0] / nb_pool[1]) * (shapey / nb_pool[0] / nb_pool[1]), 512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(512, nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's train the model using SGD + momentum (how original).\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real time data augmentation\n",
      "----------------------------------------\n",
      "Epoch 0\n",
      "----------------------------------------\n",
      "Training...\n",
      " 800/3180 [======>.......................] - ETA: 14587s - train loss: 6.1506"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print(\"Not using data augmentation or normalization\")\n",
    "\n",
    "    X_train = X_train.astype(\"float32\")\n",
    "    X_test = X_test.astype(\"float32\")\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "\n",
    "else:\n",
    "    print(\"Using real time data augmentation\")\n",
    "\n",
    "    # this will do preprocessing and realtime data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    for e in range(nb_epoch):\n",
    "        print('-'*40)\n",
    "        print('Epoch', e)\n",
    "        print('-'*40)\n",
    "        print(\"Training...\")\n",
    "        # batch train with realtime data augmentation\n",
    "        progbar = generic_utils.Progbar(X_train.shape[0])\n",
    "        for X_batch, y_batch in datagen.flow(X_train, y_train):\n",
    "            loss = model.train_on_batch(X_batch, y_batch)\n",
    "            progbar.add(X_batch.shape[0], values=[(\"train loss\", loss)])\n",
    "\n",
    "        print(\"Testing...\")\n",
    "        # test time!\n",
    "        progbar = generic_utils.Progbar(X_test.shape[0])\n",
    "        for X_batch, y_batch in datagen.flow(X_test, y_test):\n",
    "            score = model.test_on_batch(X_batch, y_batch)\n",
    "            progbar.add(X_batch.shape[0], values=[(\"test loss\", score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image = features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ypredict = model.predict(test_image, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfpredict = pd.DataFrame(ypredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6924, 447)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../Data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfpredict.columns = sample_submission.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfpredict['Image'] = foundlist_test\n",
    "dfpredict.to_csv('../Data/predict_CNNbenchmark.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6925, 448)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6924, 448)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11468"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
